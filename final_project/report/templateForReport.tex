% ****** Start of file templateForReport.tex ******

% TeX'ing this file requires that you have all prerequisites
% for REVTeX 4.1 installed
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex templateForReport.tex
%  2)  bibtex templateForReport
%  3)  latex templateForReport.tex
%  4)  latex templateForReport.tex
%
\documentclass[%
 reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose,
%preprint,
%showpacs,preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
 aps,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4-1}

\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{hyperref}% add hypertext capabilities
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage[labelfont=bf]{caption}
\bibliographystyle{abbrvnat}
\newcommand{\btheta}{\boldsymbol{\theta}}
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

%\usepackage[showframe,%Uncomment any one of the following lines to test
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall,% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}

\begin{document}

\title{Exploring \textsc{Monte-Carlo}-integration techniques in Bayesian model selection}% Force line breaks with \\
%\thanks{A footnote to the article title}%

\author{Jakob Krause}
 \homepage{http://www.github.com/krausejm}
 \email{krause@hiskp.uni-bonn.de}
\author{Dominic Schüchter}
 \homepage{http://www.github.com/dschuechter}
 \email{dschuechter@uni-bonn.de}

\date{\today}% It is always \today, today,
             %  but any date may be explicitly specified

\begin{abstract}
  An article usually includes an abstract, a concise summary of the work
  covered at length in the main body of the article.
  \begin{description}
  \item[Usage]
    Secondary publications and information retrieval purposes.
  \item[Structure]
    You may use the \texttt{description} environment to structure your abstract;
    use the optional argument of the \verb+\item+ command to give the category of each item.
  \end{description}
\end{abstract}
\maketitle

%\tableofcontents

\section{\label{sec:intro}Introduction}
\noindent In physics, one is often faced with the problem of \emph{Model Selection} for a given data set. That means finding a mathematical description of the data, which on the one hand sufficiently characterizes the data structure and on the other hand satisfies the expected dependencies. This is by no means a trivial task; one has to understand the underlying physical model beforehand to not make the mistake of choosing a too complicated model although it may seemingly fit the data. At the same time too trivial assumptions can also lead in the wrong direction. Compactly this problem can be formulated in the following way (adapted from \cite[Chap. 4]{sivia}):

\begin{center}
	\emph{Alice has a theory; Bob also has a theory, but with an adjustable parameter $\lambda$. Whose theory should we prefer on the basis of data D?}
\end{center}


 {\color{red}
\textsc{Bayes}ian inference provides quantitative measures for this model-selection problem, e.g. the \textsc{Bayes}-factor and the \textsc{Bayes}-complexity}, these have among others been successfully used in astronomy as can be found in \cite{trotta,kunz,Trotta_2008} respectively. In this paper we will investigate two simulated example problems and apply various measures of bayesian model selection as to find out the true underlying model which was used to generate the simulated data. We will  focus on the numerical evaluation of such problems, especially\textsc{ Monte-Carlo} techniques.
\section{Theory}
\noindent In the following we will give a short introduction into \textsc{Bayes} theorem and the underlying concepts of parameter estimation and model selection.
\subsection{Bayes' Theorem}
\noindent The fundamental equation of \textsc{Bayesian} statistics -- for a dataset $y$ and parameters $\boldsymbol{\theta}$ -- is given by \textsc{Bayes} Theorem.
\begin{equation}
\label{eq:bayes}
\text{prob}(\boldsymbol{\theta} | y) =	p(\boldsymbol{\theta} | y) = \frac{p(y|\boldsymbol{\theta})\cdot p(\boldsymbol{\theta})}{p(y)} 
\end{equation}
Where $p(\boldsymbol{\theta} | y) $ is the posterior probability for parameters $\boldsymbol{\theta}$ given the data $y$, $p(y|\boldsymbol{\theta})$ is the likelihood that the data fits a model with parameters $\boldsymbol{\theta}$, $p(\boldsymbol{\theta})$ is the prior probability of $\boldsymbol{\theta}$ and $p(y)= \int_{-\infty}^{+\infty}\text{d}\boldsymbol{\theta} p(y|\boldsymbol{\theta})p(\boldsymbol{\theta})$ is the marginal likelihood which acts as a normalization.  In the case of parameter selection, the normalization can often be neglected since it is only a  constant. In the case of the model comparison it is a crucial quantity, as we will disuss in section (\ref{sec:Model_comparison}) \cite[Chap. 2]{sivia}. 

\subsection{Parameter estimation}
\noindent Assume we want to find the best parameters for a given dataset $y$ and model $M$. Eq. \eqref{eq:bayes} then can be written as
\begin{equation}\label{eq:PDF}
	p(\boldsymbol{\theta} | y,M) = \frac{p(y|\boldsymbol{\theta},M)\cdot p(\boldsymbol{\theta}|M)}{p(y|M)}.
\end{equation}
Evaluating this equation will give probability density functions (PDFs) 
\begin{equation}
\label{eq:marp}
	p(\theta_i|y,M)=\int p(\boldsymbol{\theta}|y,M)\prod_{j\neq i}\text{d}{\theta_j}
\end{equation}
 for each parameter $\theta_i$.  Because of equation \eqref{eq:marp} $p(\theta|D,M)$ is also called \emph{marginal posterior}. From this one can find the best fit value either by finding the value of $\theta$ for which the marginal posterior is maximized or by calculating the mean with respect to the marginal posterior.

\begin{align}
	\begin{split}
		p(\theta|y,M)=\max \Leftrightarrow \theta=\hat{\theta}\\
		\langle\theta\rangle=\int_{-\infty}^{\infty}\text{d}\theta  p(\theta|y,M)\cdot\theta
	\end{split}
\end{align}
Throughout this paper we will use $\langle\theta\rangle$ as our best fit estimate. \cite{sivia}

\subsection{Model comparison}\label{sec:Model_comparison}
\noindent To compare two (or more) competing models $M_i$ that describe a dataset $D$ let us write \textsc{Bayes} theorem once again
\begin{equation}
	p(M_i|y)=\frac{p(M_i)\cdot p(y|M_i)}{p(y)}.
\end{equation}
We recognize $p(y|M_i)$ as the marginal likelihood of the model $M_i$. Let now  the two competing models be those of Alice and Bob introduced in section \eqref{sec:intro}.Thus, $$p(y|M_i)=\int_{-\infty}^{\infty}\text{d}\lambda p(y|\lambda, M)\cdot p(\lambda|M)$$
follows \cite[Chap. 3]{sivia}.
\subsubsection{\textbf{Bayes Factor}}
One way of comparing two models is to compare their posterior odds, that is the ratio {\color{red} quote lecture A. Wirzba?} \begin{equation}\label{eq:bf}O_{ij}:=\underbrace{\frac{p(M_i|y)}{p(M_j|y)}}_{\text{posterior odds}}=\underbrace{\frac{p(y|M_i)}{p(y|M_j)}}_{\text{\textsc{Bayes} Factor}}\cdot\underbrace{\frac{p(M_i)}{p(M_j)}}_{\text{prior odds}}=B_{ij}\cdot\frac{p(M_i)}{p(M_j)}.\end{equation}
Usually we can assume the prior odds to be $\sim 1$ because we do not favor one model over the other just on prior beliefs. With this equation \eqref{eq:bf} simply becomes $$O_{ij}=B_{ij}.$$
Calculating $B_{ij}$ will be referred to as calculating the \textsc{Bayes} factor \emph{in favor of} model $M_i$. We can then evaluate the result of $B_{ij}$ as follows 
\begin{equation*}
	B_{ij}=B_{ji}^{-1}=\begin{cases} \geq 1 & \text{model } M_i \text{ favored}\\
	 <1 & \text{model } M_j \text{ favored}
	\end{cases}
\end{equation*}

Nevertheless a \textsc{Bayes} Factor $\geq1$ does not mean that the favored model is far superior. There is an empirical scale which points to the strength of evidence for a given $B_{ij}$. This is displayed in table \eqref{tab:bf}.


\begin{table}[htbp]

	\centering
	{\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{|c|c|c|c|}
		\hline
		$|\ln B_{ij}|$& Odds & Probability & Strength of evidence \\
		\hline
		$< 1.0$& $ \lesssim 3:1$ & $< 0.750$  & Inconclusive  \\
		$1.0$ & $\sim 3:1$ & $0.750$ & Weak evidence  \\
		$2.5$& $\sim 12:1$ & $0.923$ & Moderate evidence \\
		$5.0$& $\sim 150:1$ & $0.993$ & Strong evidence \\
		\hline
	\end{tabular}}
\caption{Empirical scale for evaluating the strength of evidence when comparing two models $M_i$ vs. $M_j$, adapted from \cite{Trotta_2008}}
\label{tab:bf}
\end{table}
{\color{red} Bayes factor vor allem attraktiv für genestete modelle}


\subsubsection{\textbf{Bayes Complexity}}
When comparing models with a different amount of parameters, we obviously denote more parameters as more complex. A fundamental question of model-selection is then if the given data supports more or less parameters. A na\"ive measure of complexity would be the number of free parameters a model has, we denote this as $\mathcal{C}_0$. A more sophisticated measure of complexity is given by the so called \textsc{Bayesian} complexity, first introduced by Spiegelhalter et al \cite{Spiegelhalter}, which can be written as \cite{kunz} 
\begin{equation}\label{eq:Bayes_Complexity}
	\mathcal{C}_b=-2\int \text{d}\boldsymbol{\theta} p(\boldsymbol{\theta}|y,M)\log(\mathcal{L}(\boldsymbol{\theta}))+2\log(\mathcal{L}(\boldsymbol{\tilde{\theta}})),
\end{equation}
with  the likelihood $\mathcal{L}(\boldsymbol{\theta})=p(D|\boldsymbol{\theta},M)$ and $\boldsymbol{\tilde{\theta}}=\langle\boldsymbol{\theta}\rangle$. $\mathcal{C}_b$ describes how many model parameters the data is able to constrain \cite{kunz} and is thus a useful tool for examining models with an increasing number of parameters. If we define a $\chi^2$ as $\mathcal{L}(\boldsymbol{\theta})\propto \exp(-\chi^2/2)$, we can write 
\begin{equation}\label{eq:Bayes_Complexity_alt}
	\mathcal{C}_b=\overline{\chi^2(\boldsymbol{\theta})}-\chi^2(\boldsymbol{\tilde{\theta}}),
\end{equation}
where $\overline{\chi}$ denotes the mean taken over the posterior PDF. 
The definition of $\mathcal{C}_b$ is chosen such that $\mathcal{C}_b\to\mathcal{C}_0$ for highly informative data \cite{kunz}.

\section{Methods}
\noindent We will now describe the functions of the used algorithms for the model selection. Since the implementation of the so called nested sampling is sufficiently dealt with by {\color{red} Gruppe - Bayesian parameter fitting} our implementation uses the \texttt{PyMC3}-Python Library \cite{PyMC3}.  \texttt{PyMC3} offers simple solutions to create models and a wide variety of sampling algorithms. Furthermore the \texttt{ArviZ}-Library provides methods for posterior analysis and visualization \cite{ArviZ}.

 \subsection{Monte-Carlo Sampling}
\noindent First, the goal of \textsc{Monte-Carlo} sampling is discussed. Often equations \eqref{eq:marp}, \eqref{eq:Bayes_Complexity} and \eqref{eq:Bayes_Complexity_alt} have no closed analytical solutions, so we are left with a numerical ansatz (or analytical approximations) \cite{Toussaint}. One possibility is given by Markov-Chain-Monte-Carlo Sampling (MCMC) {\color{red} \cite{??}}. The main idea is to generate a chain of parameter samples $\boldsymbol{\theta}^{(t)}$ that follow the posterior PDF \eqref{eq:PDF}. For such a chain the mean with respect to the posterior is given by 
 \begin{equation}
 	\langle \boldsymbol{\theta}\rangle\approx \int p(\boldsymbol{\theta} | y)\boldsymbol{\theta}d\boldsymbol{\theta}=\frac{1}{N}\sum_{t=0}^{N-1}\boldsymbol{\theta}^{(t)},
 \end{equation}
since the samples follow the PDF $p(\boldsymbol{\theta} | y)$. Analogously the expectation value of any function with respect to the posterior is
 \begin{equation}
	\langle f(\boldsymbol{\theta})\rangle\approx\frac{1}{N}\sum_{t=0}^{N-1}f(\boldsymbol{\theta}^{(t)}).
\end{equation}
Having established a \textsc{Markov} chain, one can compute the marginal posterior \eqref{eq:marp} by binning $\theta_i$ in the given parameter range and ignoring all other parameters \cite{Trotta_2008}. 

\subsection{Metropolis-Hastings Algorithm}
\noindent Because the \textsc{Metropolis-Hastings}-algorithm is one of the fundamentals of understanding SMC, see section \eqref{sec:SMC}, we briefly state it here. The main characterization of a \textsc{Markov} chain -- which consists of random parameters $\boldsymbol{\theta}^{(t)}$ -- is that each element is only determined by the previous element. In our case we want to sample in the parameter space according to the distribution $p(\btheta|y,M):=p(\btheta)$ \eqref{eq:PDF}. We can achieve this by randomly proposing a new vector in parameter space $\btheta'$  according to a arbitrary proposal distribution $p_p(\boldsymbol{a}|\boldsymbol{b})$ and accept it with a probability $$A(\btheta',\btheta^{(t)})=\min\left(1,\frac{p(\btheta')p_p(\btheta^{(t)}|\btheta')}{p(\btheta^{(t)})p_p(\btheta'|\btheta^{(t)})}\right).$$
This ensures the sampled values follow the desired PDF \cite{Toussaint}. This is only a very brief overview of MCMC. More information on the underlying theory can be found e.g. in \cite{neal}

\subsection{Sequential Monte Carlo (SMC)}\label{sec:SMC}
 \noindent For our purposes we chose the \emph{Sequential Monte Carlo} sampling algorithm provided by \texttt{PyMC3} \cite{PyMC3_SMC}, because it grants easy access to the marginal likelihood. This in turn is needed for model comparison via the \textsc{Bayes}-factor.
 
 Since the SMC algorithm joins several statistical concepts, including \emph{importance sampling}, \emph{tempering} and and MCMC kernel (\textsc{Metropolis-Hastings}) \cite{PyMC3_SMC}, it is a highly non-trivial algorithm. Thus, a detailed description is beyond the scope of this paper. We will now sketch the main idea of the algorithm. 
 First let us introduce an auxiliary \emph{parameter} $\beta$ and write equation \eqref{eq:PDF} as 
   $$p(\btheta|y)_\beta=\frac{p(y|\btheta)^\beta\cdot p(\btheta)}{Z_\beta},$$
   with $Z_\beta=\int\text{d}\btheta p(y|\btheta)^\beta\cdot p(\btheta)$. For $\beta=1$ we get the same equation as before, that is $p(\btheta|y)_\beta=p(\btheta|y)$. The idea is to gradually sample from $\beta=0$ to $\beta=1$ using $\beta$ to control the transition from an easy to sample distribution to a harder one. The final result is a collection of samples from the true posterior \cite{PyMC3_SMC}. We can then estimate the marginal likelihood as \cite{SMC_PEPE} $$\hat{p}(y)=\prod_{i}\widehat{\frac{Z_{\beta_i}}{Z_{\beta_{i-1}}}}.$$
   The hat denotes, that this is a numerical estimation of $p(y)$ \cite{PyMC3_SMC}. Using SMC we can in one run do parameter inference and also compare different models using the \textsc{Bayes}-factor \eqref{eq:bf}.
 
\subsection{Savage Dickey Density Ration (SDDR)}
Now we introduce an alternative way of computing the \textsc{Bayes}-factor \eqref{eq:bf} for \emph{nested} models; Consider model $M_j$ with free parameters $\omega,\psi$ and a submodel $M_i$ with one free parameter $\psi$ and fixed $\omega=\omega_\star$. Let us furhter assume seperable priors (which is usually the case \cite{trotta}) $$p(\omega,\psi|M_j)=p(\omega|M_j)p(\psi|M_i).$$
We can then write the \textsc{Bayes}-factor as \cite{trotta} \begin{equation}
	\label{eq:sddr}
	B_{ij}=B_{ji}^{-1}=\frac{p(\omega|y,M_1)}{p(\omega|M_1)}\bigg|_{\omega=\omega_\star}  \text{\hfill (SDDR)}.
\end{equation}

\section{Examples}

\subsection{Betabinomial example (coin flip)}
Let us now consider as a starting example, the flipping of a two-sided coin, i.e. an experiment where we can measure either heads (H) or tails (T) with $50\%$ probability, respectively. This, while simple, allows us an intuitive approach to Bayesian inference and model selection as well as to the MCMC techniques discussed before. Furthermore is this example easily altered to many real-life problems, such as birth rates, $\dots$, or anything with the option of either success or failure.
\subsubsection{Analytical approach?}
Assume we throw a coin 20 times. We observe 6 H and 14 T. "Is this a fair coin?" might be a question to ask yourself since the bias in outcome is quite large. Naively expecting a fair coin we could assign a \emph{prior} to the probability of heads $\theta$ as centred around $0.5$, so for example a gaussian with $\mu=0.5,\sigma=0.1$.  
\subsubsection{Numerical approach}

\subsection{Fitting a polynomial of unknown degree}
\subsubsection{Analytical approach?}
\subsubsection{Numerical approach}

\section{Discussion}

\section{Summary}


\bibliography{refs}
\end{document}
%
% ****** End of file templateForReport.tex ******
