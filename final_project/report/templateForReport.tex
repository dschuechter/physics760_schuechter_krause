% ****** Start of file templateForReport.tex ******

% TeX'ing this file requires that you have all prerequisites
% for REVTeX 4.1 installed
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex templateForReport.tex
%  2)  bibtex templateForReport
%  3)  latex templateForReport.tex
%  4)  latex templateForReport.tex
%
\documentclass[%
 reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose,
%preprint,
%showpacs,preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
 aps,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4-1}

\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{hyperref}% add hypertext capabilities
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{amsmath}
\bibliographystyle{abbrvnat}

%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

%\usepackage[showframe,%Uncomment any one of the following lines to test
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall,% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}

\begin{document}

\title{Exploring \textsc{Monte-Carlo}-integration techniques in Bayesian model selection}% Force line breaks with \\
%\thanks{A footnote to the article title}%

\author{Jakob Krause}
 \homepage{http://www.github.com/krausejm}
 \email{krause@hiskp.uni-bonn.de}
\author{Dominic Sch√ºchter}
 \homepage{http://www.github.com/dschuechter}
 \email{dschuechter@uni-bonn.de}

\date{\today}% It is always \today, today,
             %  but any date may be explicitly specified

\begin{abstract}
  An article usually includes an abstract, a concise summary of the work
  covered at length in the main body of the article.
  \begin{description}
  \item[Usage]
    Secondary publications and information retrieval purposes.
  \item[Structure]
    You may use the \texttt{description} environment to structure your abstract;
    use the optional argument of the \verb+\item+ command to give the category of each item.
  \end{description}
\end{abstract}
\maketitle

%\tableofcontents

\section{\label{sec:level1}Introduction}
\noindent In physics, one is often faced with the problem of \emph{Model Selection} for a given data set. That means finding a mathematical description of the data, which on the one hand sufficiently characterizes the data structure and on the other hand satisfies the expected dependencies. This is by no means a trivial task; one has to understand the underlying physical model beforehand to not make the mistake of choosing a too complicated model although it may seemingly fit the data. At the same time too trivial assumptions can also lead in the wrong direction. Compactly this problem can be formulated in the following way (adapted from \cite[Chap. 4]{sivia}):

\begin{center}
	\emph{Alice has a theory; Bob also has a theory, but with an adjustable parameter $\lambda$. Whose theory should we prefer on the basis of data D?}
\end{center}


 {\color{red}
\textsc{Bayes}ian inference provides quantitative measures for this model-selection problem, e.g. the \textsc{Bayes}-factor and the \textsc{Bayes}-complexity}, these have among others been successfully used in astronomy as can be found in \cite{trotta,kunz} respectively. In this paper we will investigate two simulated example problems and apply various measures of bayesian model selection as to find out the true underlying model which was used to generate the simulated data. We will  focus on the numerical evaluation of such problems, especially\textsc{ Monte-Carlo} techniques.
\section{Theory}
\noindent In the following we will give a short introduction into \textsc{Bayes Theory} and the underlying concepts of model selection.
\subsection{Bayes' Theorem}
\noindent The fundamental equation of \textsc{Bayesian} statistics -- for a dataset $y$ and parameters $\boldsymbol{\theta}$ -- is given by \textsc{Bayes} Theorem.
\begin{equation}
\text{prob}(\boldsymbol{\theta} | y) =	p(\boldsymbol{\theta} | y) = \frac{p(y|\boldsymbol{\theta})\cdot p(\boldsymbol{\theta})}{p(y)} 
\end{equation}
Where $p(\boldsymbol{\theta} | y) $ is the posterior probability for parameters $\boldsymbol{\theta}$ given the data $y$, $p(y|\boldsymbol{\theta})$ is the likelihood that the data fits a model with parameters $\boldsymbol{\theta}$, $p(\boldsymbol{\theta})$ is the prior probability of $\boldsymbol{\theta}$ and $p(y)= \int_{-\infty}^{+\infty}\text{d}\boldsymbol{\theta} p(y|\boldsymbol{\theta})p(\boldsymbol{\theta})$ is the marginal likelihood which acts as a normalization.  In the case of parameter selection, the normalization can often be neglected since it is only a  constant. In the case of the model comparison it is a crucial quantity, as we will disuss in section (\ref{sec:Model_comparison}) \cite[Chap. 2]{sivia}. 

\subsection{Parameter estimation}
\noindent 
\subsection{Model comparison}\label{sec:Model_comparison}
\subsubsection{Bayes Factor}
\subsubsection{Bayes Complexity}



\section{Methods}
\noindent We will now describe the functions of the used algorithms for the model selection. Since the implementation of the so called nested sampling is sufficiently dealt with by {\color{red} Gruppe - Bayesian parameter fitting} our implementation uses the \texttt{PyMC3}-Python Library \cite{PyMC3}.
 
\subsection{Monte-Carlo integration}
Here we will explain Monte-Carlo sampling, that is \emph{Sequential Monte Carlo} and therein \textsc{Metropolis-Hastings}. its probably better to put these two subsections in separate sections.

\subsection{Savage Dickey Density Ration (SDDR)}


\section{Examples}

\subsection{Betabinomial example (coin flip)}
Let us now consider as a starting example, the flipping of a two-sided coin, i.e. an experiment where we can measure either heads (H) or tails (T) with $50\%$ probability, respectively. This, while simple, allows us an intuitive approach to Bayesian inference and model selection as well as to the MCMC techniques discussed before. Furthermore is this example easily altered to many real-life problems, such as birth rates, $\dots$, or anything with the option of either success or failure.
\subsubsection{Analytical approach?}
Assume we throw a coin 20 times. We observe 6 H and 14 T. "Is this a fair coin?" might be a question to ask yourself since the bias in outcome is quite large. Naively expecting a fair coin we could assign a \emph{prior} to the probability of heads $\theta$ as centred around $0.5$, so for example a gaussian with $\mu=0.5,\sigma=0.1$.  
\subsubsection{Numerical approach}

\subsection{Fitting a polynomial of unknown degree}
\subsubsection{Analytical approach?}
\subsubsection{Numerical approach}

\section{Discussion}

\section{Summary}


\bibliography{refs}
\end{document}
%
% ****** End of file templateForReport.tex ******
