% ****** Start of file templateForReport.tex ******

% TeX'ing this file requires that you have all prerequisites
% for REVTeX 4.1 installed
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex templateForReport.tex
%  2)  bibtex templateForReport
%  3)  latex templateForReport.tex
%  4)  latex templateForReport.tex
%
\documentclass[%
 reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose,
%preprint,
%showpacs,preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
 aps,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4-1}
\usepackage{boxhandler}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{hyperref}% add hypertext capabilities
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage[labelfont=bf]{caption}
\usepackage{subcaption}
\bibliographystyle{abbrvnat}
\graphicspath{{figs/}}  
\newcommand{\btheta}{\boldsymbol{\theta}}


%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

%\usepackage[showframe,%Uncomment any one of the following lines to test
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall,% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}

\begin{document}

\title{Exploring \textsc{Monte-Carlo}-integration techniques in Bayesian model selection}% Force line breaks with \\
%\thanks{A footnote to the article title}%

\author{Jakob Krause}
 \homepage{http://www.github.com/krausejm}
 \email{krause@hiskp.uni-bonn.de}
\author{Dominic Schüchter}
 \homepage{http://www.github.com/dschuechter}
 \email{dschuechter@uni-bonn.de}

\date{\today}% It is always \today, today,
             %  but any date may be explicitly specified

\begin{abstract}
  An article usually includes an abstract, a concise summary of the work
  covered at length in the main body of the article.
  \begin{description}
  \item[Usage]
    Secondary publications and information retrieval purposes.
  \item[Structure]
    You may use the \texttt{description} environment to structure your abstract;
    use the optional argument of the \verb+\item+ command to give the category of each item.
  \end{description}
\end{abstract}
\maketitle

%\tableofcontents

\section{\label{sec:intro}Introduction}
\noindent In physics, one is often faced with the problem of \emph{Model Selection} for a given data set. That means finding a mathematical description of the data, which on the one hand sufficiently characterizes the data structure and on the other hand satisfies the expected dependencies. This is by no means a trivial task; one has to understand the underlying physical model beforehand to not make the mistake of choosing a too complicated model although it may seemingly fit the data. At the same time too trivial assumptions can also lead in the wrong direction. Compactly this problem can be formulated in the following way (adapted from \cite[Chap. 4]{sivia}):

\begin{center}
	\emph{Alice has a theory; Bob also has a theory, but with an adjustable parameter $\lambda$. Whose theory should we prefer on the basis of data D?}
\end{center}



For this model-selection problem \textsc{Bayesian} inference provides quantitative measures, e.g. the \textsc{Bayes}-factor and the \textsc{Bayes}-complexity, these have among others been successfully used in astronomy as can be found in \cite{trotta,kunz,Trotta_2008} respectively. In this paper we will investigate two simulated example problems and apply various measures of bayesian model selection as to find out the true underlying model which was used to generate the simulated data. We will  focus on the numerical evaluation of such problems, especially\textsc{ Monte-Carlo} techniques.
\section{Theory}
\noindent In the following we will give a short introduction into \textsc{Bayes} theorem and the underlying concepts of parameter estimation and model selection.
\subsection{Bayes' Theorem}
\noindent The fundamental equation of \textsc{Bayesian} statistics -- for a dataset $y$ and parameters $\boldsymbol{\theta}$ -- is given by \textsc{Bayes} Theorem.
\begin{equation}
\label{eq:bayes}
\text{prob}(\boldsymbol{\theta} | y) =	p(\boldsymbol{\theta} | y) = \frac{p(y|\boldsymbol{\theta})\cdot p(\boldsymbol{\theta})}{p(y)} 
\end{equation}
Where $p(\boldsymbol{\theta} | y) $ is the posterior probability for parameters $\boldsymbol{\theta}$ given the data $y$, $p(y|\boldsymbol{\theta})$ is the likelihood that the data fits a model with parameters $\boldsymbol{\theta}$, $p(\boldsymbol{\theta})$ is the prior probability of $\boldsymbol{\theta}$ and $p(y)= \int_{-\infty}^{+\infty}\text{d}\boldsymbol{\theta} p(y|\boldsymbol{\theta})p(\boldsymbol{\theta})$ is the marginal likelihood which acts as a normalization.  In the case of parameter selection, the normalization can often be neglected since it is only a  constant. In the case of the model comparison it is a crucial quantity, as we will disuss in subsection (\ref{sec:Model_comparison}) \cite[Chap. 2]{sivia}. 

\subsection{Parameter estimation}
\noindent Assume we want to find the best parameters for a given dataset $y$ and model $M$. Eq. \eqref{eq:bayes} then can be written as
\begin{equation}\label{eq:PDF}
	p(\boldsymbol{\theta} | y,M) = \frac{p(y|\boldsymbol{\theta},M)\cdot p(\boldsymbol{\theta}|M)}{p(y|M)}.
\end{equation}
Evaluating this equation will give probability density functions (PDFs) 
\begin{equation}
\label{eq:marp}
	p(\theta_i|y,M)=\int p(\boldsymbol{\theta}|y,M)\prod_{j\neq i}\text{d}{\theta_j}
\end{equation}
 for each parameter $\theta_i$.  Because of equation \eqref{eq:marp} $p(\theta|D,M)$ is also called \emph{marginal posterior}. From this one can find the best fit value either by finding the value of $\theta$ for which the marginal posterior is maximized or by calculating the mean with respect to the marginal posterior.

\begin{align}
	\begin{split}
		p(\theta|y,M)=\max \Leftrightarrow \theta=\hat{\theta}\\
		\langle\theta\rangle=\int_{-\infty}^{\infty}\text{d}\theta  p(\theta|y,M)\cdot\theta
	\end{split}
\end{align}
Throughout this paper we will use $\langle\theta\rangle$ as our best fit estimate. \cite{sivia}

\subsection{Model comparison}\label{sec:Model_comparison}
\noindent To compare two (or more) competing models $M_i$ that describe a dataset $D$ let us write \textsc{Bayes} theorem once again
\begin{equation}
	p(M_i|y)=\frac{p(M_i)\cdot p(y|M_i)}{p(y)}.
\end{equation}
We recognize $p(y|M_i)$ as the marginal likelihood of the model $M_i$. Let now  the two competing models be those of Alice and Bob introduced in section \eqref{sec:intro}.Thus, $$p(y|M_i)=\int_{-\infty}^{\infty}\text{d}\lambda p(y|\lambda, M)\cdot p(\lambda|M)$$
follows \cite[Chap. 3]{sivia}.
\subsubsection{\textbf{Bayes Factor}}
One way of comparing two models is to compare their posterior odds, that is the ratio \cite{Trotta_2008} \begin{equation}\label{eq:bf}O_{ij}:=\underbrace{\frac{p(M_i|y)}{p(M_j|y)}}_{\text{posterior odds}}=\underbrace{\frac{p(y|M_i)}{p(y|M_j)}}_{\text{\textsc{Bayes} Factor}}\cdot\underbrace{\frac{p(M_i)}{p(M_j)}}_{\text{prior odds}}=B_{ij}\cdot\frac{p(M_i)}{p(M_j)}.\end{equation}
Usually we can assume the prior odds to be $\sim 1$ because we do not favor one model over the other just on prior beliefs. With this equation \eqref{eq:bf} simply becomes $$O_{ij}=B_{ij}.$$
Calculating $B_{ij}$ will be referred to as calculating the \textsc{Bayes} factor \emph{in favor of} model $M_i$. We can then evaluate the result of $B_{ij}$ as follows 
\begin{equation*}
	B_{ij}=B_{ji}^{-1}=\begin{cases} \geq 1 & \text{model } M_i \text{ favored}\\
	 <1 & \text{model } M_j \text{ favored}
	\end{cases}
\end{equation*}

Nevertheless a \textsc{Bayes} Factor $\geq1$ does not mean that the favored model is far superior. There is an empirical scale which points to the strength of evidence for a given $B_{ij}$. This is displayed in table \eqref{tab:bf}.


\begin{table}[htbp]

	\centering
	{\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{|c|c|c|c|}
		\hline
		$|\ln B_{ij}|$& Odds & Probability & Strength of evidence \\
		\hline
		$< 1.0$& $ \lesssim 3:1$ & $< 0.750$  & Inconclusive  \\
		$1.0$ & $\sim 3:1$ & $0.750$ & Weak evidence  \\
		$2.5$& $\sim 12:1$ & $0.923$ & Moderate evidence \\
		$5.0$& $\sim 150:1$ & $0.993$ & Strong evidence \\
		\hline
	\end{tabular}}
\caption{Empirical scale for evaluating the strength of evidence when comparing two models $M_i$ vs. $M_j$, adapted from \cite{Trotta_2008}}
\label{tab:bf}
\end{table}
%{\color{red} Bayes factor vor allem attraktiv für genestete modelle}


\subsubsection{\textbf{Bayes Complexity}}
When comparing models with a different amount of parameters, we obviously denote more parameters as more complex. A fundamental question of model-selection is then if the given data supports more or less parameters. A na\"ive measure of complexity would be the number of free parameters a model has, we denote this as $\mathcal{C}_0$. A more sophisticated measure of complexity is given by the so called \textsc{Bayesian} complexity, first introduced by Spiegelhalter et al \cite{Spiegelhalter}, which can be written as \cite{kunz} 
\begin{equation}\label{eq:Bayes_Complexity}
	\mathcal{C}_b=-2\int \text{d}\boldsymbol{\theta} p(\boldsymbol{\theta}|y,M)\log(\mathcal{L}(\boldsymbol{\theta}))+2\log(\mathcal{L}(\boldsymbol{\tilde{\theta}})),
\end{equation}
with  the likelihood $\mathcal{L}(\boldsymbol{\theta})=p(D|\boldsymbol{\theta},M)$ and $\boldsymbol{\tilde{\theta}}=\langle\boldsymbol{\theta}\rangle$. $\mathcal{C}_b$ describes how many model parameters the data is able to constrain \cite{kunz} and is thus a useful tool for examining models with an increasing number of parameters. If we define a $\chi^2$ as $\mathcal{L}(\boldsymbol{\theta})\propto \exp(-\chi^2/2)$, we can write 
\begin{equation}\label{eq:Bayes_Complexity_alt}
	\mathcal{C}_b=\overline{\chi^2(\boldsymbol{\theta})}-\chi^2(\boldsymbol{\tilde{\theta}}),
\end{equation}
where $\overline{\chi}$ denotes the mean taken over the posterior PDF. 
The definition of $\mathcal{C}_b$ is chosen such that $\mathcal{C}_b\to\mathcal{C}_0$ for highly informative data \cite{kunz}.

\section{Methods}\label{sec:meth}
\noindent We will now describe the functions of the used algorithms for the model selection. Since the implementation of the so called nested sampling is sufficiently dealt with by {\color{red} Gruppe - Bayesian parameter fitting} our implementation uses the \texttt{PyMC3}-Python Library \cite{PyMC3}.  \texttt{PyMC3} offers simple solutions to create models and a wide variety of sampling algorithms. Furthermore the \texttt{ArviZ}-Library provides methods for posterior analysis and visualization \cite{ArviZ}.

 \subsection{Monte-Carlo Sampling}
\noindent First, the goal of \textsc{Monte-Carlo} sampling is discussed. Often equations \eqref{eq:marp}, \eqref{eq:Bayes_Complexity} and \eqref{eq:Bayes_Complexity_alt} have no closed analytical solutions, so we are left with a numerical ansatz (or analytical approximations) \cite{Toussaint}. One possibility is given by Markov-Chain-Monte-Carlo Sampling (MCMC) {\color{red} \cite{??}}. The main idea is to generate a chain of parameter samples $\boldsymbol{\theta}^{(t)}$ that follow the posterior PDF \eqref{eq:PDF}. For such a chain the mean with respect to the posterior is given by 
 \begin{equation}
 	\langle \boldsymbol{\theta}\rangle\approx \int p(\boldsymbol{\theta} | y)\boldsymbol{\theta}d\boldsymbol{\theta}=\frac{1}{N}\sum_{t=0}^{N-1}\boldsymbol{\theta}^{(t)},
 \end{equation}
since the samples follow the PDF $p(\boldsymbol{\theta} | y)$. Analogously the expectation value of any function with respect to the posterior is
 \begin{equation}
	\langle f(\boldsymbol{\theta})\rangle\approx\frac{1}{N}\sum_{t=0}^{N-1}f(\boldsymbol{\theta}^{(t)}).
\end{equation}
Having established a \textsc{Markov} chain, one can compute the marginal posterior \eqref{eq:marp} by binning $\theta_i$ in the given parameter range and ignoring all other parameters \cite{Trotta_2008}. 

\subsection{Metropolis-Hastings Algorithm}
\noindent So far we have discussed what we gain from sampling from the posterior distribution. We have not yet explained an algorithm how this is actually achieved.  For our purposes we chose the \emph{Sequential Monte Carlo} sampling algorithm provided by \texttt{PyMC3} \cite{PyMC3_SMC}, because it grants easy access to the marginal likelihood. This in turn is needed for model comparison via the \textsc{Bayes}-factor. Because the \textsc{Metropolis-Hastings}-algorithm is one of the fundamentals of understanding SMC, see subsection \eqref{sec:SMC}, we briefly state it here. The main characterization of a \textsc{Markov} chain -- which consists of random parameters $\boldsymbol{\theta}^{(t)}$ -- is that each element is only determined by the previous element. In our case we want to sample in the parameter space according to the distribution $p(\btheta|y,M):=p(\btheta)$ \eqref{eq:PDF}. We can achieve this by randomly proposing a new vector in parameter space $\btheta'$  according to a arbitrary proposal distribution $p_p(\boldsymbol{a}|\boldsymbol{b})$ and accept it with a probability $$A(\btheta',\btheta^{(t)})=\min\left(1,\frac{p(\btheta')p_p(\btheta^{(t)}|\btheta')}{p(\btheta^{(t)})p_p(\btheta'|\btheta^{(t)})}\right).$$
This ensures the sampled values follow the desired PDF \cite{Toussaint}. This is only a very brief overview of MCMC. More information on the underlying theory can be found e.g. in \cite{neal}

\subsection{Sequential Monte Carlo (SMC)}\label{sec:SMC}
 \noindent
 
 Since the SMC algorithm joins several statistical concepts, including \emph{importance sampling}, \emph{tempering} and and MCMC kernel (\textsc{Metropolis-Hastings}) \cite{PyMC3_SMC}, it is a highly non-trivial algorithm. Thus, a detailed description is beyond the scope of this paper. We will now sketch the main idea of the algorithm. 
 First let us introduce an auxiliary \emph{parameter} $\beta$ and write equation \eqref{eq:PDF} as 
   $$p(\btheta|y)_\beta=\frac{p(y|\btheta)^\beta\cdot p(\btheta)}{Z_\beta},$$
   with $Z_\beta=\int\text{d}\btheta p(y|\btheta)^\beta\cdot p(\btheta)$. For $\beta=1$ we get the same equation as before, that is $p(\btheta|y)_\beta=p(\btheta|y)$. The idea is to gradually sample from $\beta=0$ to $\beta=1$ using $\beta$ to control the transition from an easy to sample distribution to a harder one. The final result is a collection of samples from the true posterior \cite{PyMC3_SMC}. We can then estimate the marginal likelihood as \cite{SMC_PEPE} \begin{equation}\label{eq:with_the_hat}
   	\hat{p}(y)=\prod_{i}\widehat{\frac{Z_{\beta_i}}{Z_{\beta_{i-1}}}}.
   \end{equation}
     The hat denotes, that this is a numerical estimation of $p(y)$ \cite{PyMC3_SMC}. Using SMC we can in one run do parameter inference and also compare different models using the \textsc{Bayes}-factor \eqref{eq:bf}.
 
\subsection{Savage Dickey Density Ration (SDDR)}
Now we introduce an alternative way of computing the \textsc{Bayes}-factor \eqref{eq:bf} for \emph{nested} models; Consider model $M_j$ with free parameters $\omega,\psi$ and a submodel $M_i$ with one free parameter $\psi$ and fixed $\omega=\omega_\star$. Let us further assume seperable priors (which is usually the case \cite{trotta}) $$p(\omega,\psi|M_j)=p(\omega|M_j)p(\psi|M_i).$$
We can then write the \textsc{Bayes}-factor as \cite{trotta} \begin{equation}
	\label{eq:sddr}
	B_{ij}=B_{ji}^{-1}=\frac{p(\omega|y,M_j)}{p(\omega|M_j)}\bigg|_{\omega=\omega_\star}  \text{\hfill (SDDR)}.
\end{equation}

\section{Examples}
We will now discuss two instructive examples applying the methods described in section \eqref{sec:meth}.

\subsection{Betabinomial example (coin flip)}
Let us consider as a starting example, the flipping of a coin, i.e. an experiment where we can measure either heads ($H$) or tails ($T$) with $50\%$ probability, respectively. This, while simple, allows us an intuitive approach to Bayesian inference and model selection as well as to the MCMC techniques discussed before. Furthermore is this example easily altered to many problems with the option of either success or failure. Assume we throw a coin $N$ times.  Based on the outcome we wish to determine the probability for $H$ and draw a conclusion whether the coin is fair or, in fact, biased. We simulated data for $N=50$ and the biased coin with $p(H)=0.25$.
\subsubsection{Analytical approach}
Since this example is relatively simple we can compute the \textsc{Bayes}-factor also analytically.


Let us remember \textsc{Bayes} theorem in the context of this example where we want to compare two models $M_i,i=1,2$ which assign the following posterior to the probability of heads $p(\theta|y,M_i)$ for a given dataset $y$
$$p(\theta|y,M_i)=\frac{p(y|\theta,M_i)\cdot p(\theta|M_i)}{p(y|M_i)}.$$
Let now $M_1$ be a model which assumes a fair coin, so that the \emph{prior} is narrowly set around $\theta=0.5$. $M_2$ assumes a biased coin, that is a \emph{prior} centered around $\theta =0.25$. If we want to obtain the \textsc{Bayes}-factor we have to calculate $$p(y|M_i)=\int \text{d}\theta p(y|\theta,M_i)\cdot p(\theta|M_i) $$
because $B_{12}$ is given by \eqref{eq:bf} $$B_{12}=\frac{p(y|M_1)}{p(y|M_2)}.$$
To get an analytical solution we first have to assign \emph{prior} and \emph{likelihood} for each model. A natural ansatz for a prior $p(\theta|M_i)$ would be the Beta-distribution, since it is limited to the finite interval $[0,1]$. Its PDF is given by \cite{kormaz} \begin{align*}f(\theta;\alpha,\beta)&=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}\\&:=\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}.
\end{align*}
Where $\Gamma$ is the \emph{Gamma-function} \cite{gamma_function} and $\beta$ is the \emph{Beta-function} \cite{beta_function}.
To get a narrowly centered distribution around $0.5$ we chose $\alpha=\beta=50$. To get a distribution skewed around $0.25$ we have to choose $\beta=3\alpha-2$ \cite{wiki}, in our case $\alpha=5,\beta=13$, see figure \eqref{fig:beta_dist}.
\begin{figure}
	\centering
%	\includegraphics[width=\linewidth]{beta_dist}
	\caption{Beta-distribution as \emph{prior} $p(\theta|M_i)$ for the two different models}
	\label{fig:beta_dist}
\end{figure}
Now we will assign the \emph{likelihood} function $p(y|\theta,M)$. We can assume that each coin throw is independent of preceding coin throws and, naturally, only two outcomes are possible. Then a \emph{Binomial Distribution} is a suitable choice for our likelihood $p(y|\theta,M_i)$. If we observe $k$ heads out of $N$ coin throws ($y=(N,k)$) $$p(y|\theta,M_i)=\begin{pmatrix}N\\k
\end{pmatrix}\theta^k(1-\theta)^{N-k}.$$
Since we only are only interested in the ratio $B_{12}$ we can drop the binomial coefficient and write $$p(y|\theta, M_i)\propto \theta^k(1-\theta)^{N-k}.$$
Then the integral becomes 
\begin{align*}
	p(y|M_i)&\propto \int_{0}^{1} \text{d}\theta \frac{1}{B(\alpha,\beta)} \cdot \theta^{\alpha+k-1}\cdot (1-\theta)^{N-k+\beta-1}\\
	&=\frac{B(\alpha+k,\beta+N-k)}{B(\alpha, \beta)}.
\end{align*}
With this solution the \textsc{Bayes}-factor becomes
\begin{equation}\label{eq:anal_bf}
	B_{12}=\frac{B(\alpha_1+k,\beta_1+N-k)\cdot B(\alpha_2,\beta_2)}{B(\alpha_2+k,\beta_2+N-k)\cdot B(\alpha_1,\beta_1)}.
\end{equation}
For the biased coin $M_2$ should be superior. The analytical result of equation \eqref{eq:anal_bf} is $$B_{21}=B_{12}^{-1}=9.5839.$$

\subsubsection{Numerical approach}
\noindent We now compute the \textsc{Bayes}-factor numerically using the SMC-algorithm provided by \texttt{PyMC3}. We assigned the same \emph{priors} and \emph{likelikhoods} as in the analytical approach with a sample size of 2000 and 20 \textsc{Monte-Carlo} runs. The sampling yielded the \emph{marginal posteriors} depicted in figure \eqref{fig:coin_marp}. 
The \textsc{Bayes}-factor according to equation \eqref{eq:with_the_hat} evaluated to
$$B_{21}=B_{12}^{-1}=9.5829\pm0.4719$$
in very good agreement with the analytical result.
\begin{figure}
	\begin{subfigure}{\linewidth}
%		\includegraphics[width=\linewidth]{coin_marp_m1.pdf}
		\subcaption{}\label{fig:coin_marp_a}
	\end{subfigure}
	\begin{subfigure}{\linewidth}
%		\includegraphics[width=\linewidth]{coin_marp_m2.pdf}
		\subcaption{}\label{fig:coin_marp_b}
	\end{subfigure}
	\caption{The \emph{marginal posterior} for $\alpha=\beta=50$ \eqref{fig:coin_marp_a} and $\alpha=5, \beta=13$ \eqref{fig:coin_marp_b} of 2000 samples. HDI means highest density intervall. The highlighted green intervals denotes the expected value.}\label{fig:coin_marp}
\end{figure}
\subsection{Fitting a polynomial of unknown degree}
\subsubsection{Analytical approach?}
\subsubsection{Numerical approach}

\section{Discussion}

\section{Summary}

\newpage

\bibliography{refs}
\end{document}
%
% ****** End of file templateForReport.tex ******
